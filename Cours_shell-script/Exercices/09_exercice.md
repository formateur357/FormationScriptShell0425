# ğŸ† Exercice 2 : Analyse avancÃ©e de fichiers Logs (30 minutes)

**Objectif** : Utiliser `grep`, `awk`, `sed`, `cut`, `sort`, `uniq`, `find`, `xargs` pour rÃ©aliser un traitement complet automatisÃ© sur des fichiers `.log`.

---

## ğŸ“‹ Contexte

Votre Ã©quipe informatique vous fournit un dossier contenant plusieurs fichiers logs (`*.log`).

Vous devez :

- Rechercher et extraire toutes les erreurs critiques.
- Nettoyer les fichiers de toutes les lignes inutiles.
- Extraire des statistiques prÃ©cises sur les erreurs.
- GÃ©nÃ©rer un rapport synthÃ©tique.

---

## ğŸ“š Fichiers fournis

- Un dossier `logs/` avec plusieurs fichiers `.log` contenant :
  - des entrÃ©es `INFO`, `DEBUG`, `WARN`, `ERROR`, `FATAL`.
  - des erreurs formatÃ©es ainsi : `ERROR: [CODE] Description`.
  - quelques lignes vides et du bruit (`DEBUG`, `TRACE`, etc.).

---

## ğŸ› ï¸ Ã‰tapes Ã  rÃ©aliser

### 1. Recherche des erreurs critiques (`grep`, `find`, `xargs`)

- Recherchez toutes les lignes contenant **`ERROR`** ou **`FATAL`** dans **tous les fichiers `.log`** sous `logs/`.
- Regroupez toutes ces lignes dans un fichier unique `erreurs_critiques.log`.

---

### 2. Nettoyage des logs (`sed`)

- Supprimez, dans **tous les fichiers `.log`** :
  - Les lignes vides.
  - Les lignes contenant `DEBUG` ou `TRACE`.
- CrÃ©ez une version nettoyÃ©e de chaque fichier (exemple : `serveur1_nettoye.log`).

---

### 3. Extraction d'informations (`awk`)

Ã€ partir de `erreurs_critiques.log` :

- Extraire **le code dâ€™erreur** (ex: `[404]`, `[500]`).
- Compter le nombre d'occurrences pour chaque code d'erreur.
- Afficher un classement des codes les plus frÃ©quents, du plus courant au moins courant.

Exemple attendu :
27 [500] 18 [404] 4 [403]


---

### 4. RÃ©sumÃ© synthÃ©tique (`cut`, `sort`, `uniq`)

- Depuis tous les fichiers nettoyÃ©s, extrayez la premiÃ¨re colonne (horodatage par exemple).
- Trier ces horodatages.
- Supprimer les doublons pour obtenir toutes les heures uniques dâ€™Ã©vÃ©nements.

Exemple attendu :
2024-01-01 12:00:00 2024-01-01 12:01:15 ...

---

## ğŸ¯ Objectif final

GÃ©nÃ©rer un dossier `rapport/` contenant :

- `erreurs_critiques.log` : toutes les erreurs trouvÃ©es.
- `statistiques_erreurs.txt` : tableau des erreurs par frÃ©quence.
- `horodatages_uniques.txt` : liste triÃ©e des horodatages uniques.

---

# ğŸ”¥ Bonus (facultatif)

- Ã‰crire un script Bash `analyse_logs.sh` qui fait tout automatiquement.
- Ajouter un argument pour cibler un autre dossier que `logs/`.
- Envoyer un rapport par mail automatiquement Ã  la fin.

---

**Bonne chanceâ€¯!** ğŸš€
